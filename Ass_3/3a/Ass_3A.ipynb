{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d1dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excercise 1:\n",
    "# Define a function called split_sort_text which takes one positional parameter called text (a string).\n",
    "\n",
    "# The function:\n",
    "\n",
    "# splits the string on a space character, i.e., ' '\n",
    "\n",
    "# returns all the unique words in alphabetical order as a list.\n",
    "\n",
    "# Hint 1: There is a specific python container which does not allow for duplicates and simply removes them. Use this one.\n",
    "\n",
    "# Hint 2: There is a function which sorts items in an iterable called 'sorted'. Look at the documentation to see how it is used.\n",
    "\n",
    "# Hint 3: Don't forget to write a docstring. Please make sure that the docstring generally explains with the input is\n",
    "#    , what the function does, and what the function returns. If you want, but this is not needed to receive full points, \n",
    "#    you can use reStructuredText.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91dd47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sort_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Alphabetically sort all unique words in a string\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        text returned as an alphabetical list of unique words split by ' '.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        unique words in alphabetical order\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> split_sort_text('wassup bitch')\n",
    "    ['bitch', 'wassup']\n",
    "    >>> split_sort_text('ay ho les les go')\n",
    "    ['ay', 'go', 'ho', 'les']\n",
    "    >>> split_sort_text('imma jump 6 times this time')\n",
    "    ['6', 'imma', 'jump', 'this', 'time', 'times']\n",
    "    \"\"\"\n",
    "    text = sorted(set(text.split(' ')))\n",
    "    return text\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1321da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6', 'imma', 'jump', 'this', 'time', 'times']\n"
     ]
    }
   ],
   "source": [
    "str_1 = 'imma jump 6 times this time'\n",
    "str_2 = 'ay ho les les go'\n",
    "str_3 = 'wassup bitch'\n",
    "\n",
    "ls = (split_sort_text(str_1))\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2\n",
    "# NLTK offers a way of using WordNet in Python. Do some research (using google, because quite frankly, that's what we do very often) \n",
    "# and see if you can find out how to import it. WordNet is a computational lexicon which organizes words according to their senses \n",
    "# (collected in synsets).\n",
    "# See if you can print all the synset definitions of the lemma dog.\n",
    "\n",
    "# Make sure you have run the following cell to make sure you have installed WordNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83bb6d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "\"\"\"\n",
    "    Alphabetically sort all unique words in a string\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lemma : str\n",
    "        In the context of WordNet, a lemma (short for \"lexeme\") is a base form of a word or\n",
    "        phrase. A lemma is the canonical form of a word that is used to represent all of its\n",
    "        inflected forms (such as different tenses, plurals, etc.).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    synset defs : list\n",
    "        In the context of WordNet, a synset (short for \"synonym set\") is a set of words or\n",
    "        phrases that have the same meaning or are related in some way. Each synset is a \n",
    "        collection of synonymous words or phrases that are grouped together to represent a \n",
    "        specific concept or idea.\n",
    "        Function returns definitions of all synsets\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "def get_sysnet_defs(lemma : str) -> str:\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(lemma):\n",
    "        synonyms.append(syn.definition())\n",
    "\n",
    "    return (synonyms)\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ef8b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds', 'a dull unattractive unpleasant girl or woman', 'informal term for a man', 'someone who is morally reprehensible', 'a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll', 'a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward', 'metal supports for logs in a fireplace', 'go after with the intent to catch']\n"
     ]
    }
   ],
   "source": [
    "lemma = 'dog'\n",
    "\n",
    "i = get_sysnet_defs(lemma)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae0bb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3\n",
    "# a.) Define a function called my_word_count, which determines how often each word occurs in a string. Do not use NLTK just yet. Find a way to test it.\n",
    "# Write a helper-function called preprocess, which removes the punctuation specified by the user, and returns the same string without the unwanted characters. You call the function preprocess inside the my_word_count function.\n",
    "\n",
    "# Remember that there are string methods that you can use to get rid of unwanted characters. Test the preprocess function using the following string 'this is a (tricky) test'.\n",
    "\n",
    "# Remember how we used dictionaries to count words? If not, have a look at Chapter 10 - Dictionaries.\n",
    "\n",
    "# Make sure you split the string on a space character ' '. You then can loop over the list to count the words.\n",
    "\n",
    "# Test your function using an example string, which will tell you whether it fulfills the requirements (remove punctuation, split, count). You will get a point for good testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39d48269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def my_word_count(text : str) -> str:\n",
    "    \"\"\"\n",
    "    count occurances of individual words in a string removing punctuation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        line of text\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    count : list\n",
    "        count of unique words without punctuation\n",
    "\"\"\"\n",
    "    counter = {}\n",
    "    text = (re.sub(r'[^\\w\\s]', '', text)).split(' ')\n",
    "    for word in text:\n",
    "        if word in counter:\n",
    "            counter[word] += 1\n",
    "        else:\n",
    "            counter[word] = 1\n",
    "    \n",
    "\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa0f87dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'here': 4, 'is': 4, 'well': 1, 'I': 2, 'guess': 2, 'this': 2, 'like': 1, 'kinda': 1, 'a': 2, 'sentence': 1, 'with': 1, 'wordcounter': 1, 'it': 2}\n"
     ]
    }
   ],
   "source": [
    "text = 'here is, well, I guess this is... like (kinda) a sentence with a word-counter. here, here, here it is I guess this is it'\n",
    "i = my_word_count(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73afeb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4\n",
    "# Playing with lyrics\n",
    "\n",
    "# a.) Write a function called load_text, which opens and reads a file and returns the text in the file. It should have the file path as a parameter. Test it by loading this file: ../Data/lyrics/walrus.txt\n",
    "\n",
    "# Hint: remember it is best practice to use a context manager\n",
    "# Hint: FileNotFoundError: This means that the path you provide does not lead to an existing file on your computer. Please carefully study Chapter 14. Please determine where the notebook or Python module that you are working with is located on your computer. Try to determine where Python is looking if you provide a path such as “../Data/lyrics/walrus.txt”. Try to go from your notebook to the location on your computer where Python is trying to find the file. One tip: if you did not store the Assignments notebooks 3a and 3b in the folder “Assignments”, you would get this error.\n",
    "# b.) Write a function called replace_walrus, which takes lyrics as input and replaces every instance of 'walrus' by 'hippo' (make sure to account for upper and lower case - it is fine to transform everything to lower case). The function should write the new version of the song to a file called 'walrus_hippo.txt and stored in ../Data/lyrics.\n",
    "\n",
    "# Don't forget to add docstrings to your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af22d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def replace_walrus(text : str) -> str:\n",
    "    \"\"\"\n",
    "    replaces all instances of 'walrus' or 'Walrus' with 'hippo'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        line of text\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    text : str\n",
    "        line of text\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"walrus|Walrus\", \"hippo\", text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "\n",
    "class change_fi:\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if not os.path.exists(self.file_path):\n",
    "            raise(FileNotFoundError(f\"{self.path} does not exists.\"))\n",
    "        i = load_text(self.file_path)\n",
    "        print(i, 'i')\n",
    "        return i\n",
    "    \n",
    "    def load_text(self):\n",
    "        \"\"\"\n",
    "        reads file and writes 'hippo' \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        true : boolean\n",
    "        \"\"\"\n",
    "        with open(self.path, \"r\") as text_fi:\n",
    "            text = replace_walrus(text_fi.read())\n",
    "        with open(self.path, \"w\") as text_fi:\n",
    "            text_fi.write(text)\n",
    "            return ('text changed in: ' + self.path)\n",
    "        \n",
    "        def __exit__(self):\n",
    "            self.path.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05890541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text changed in: ./Data3/walrus.txt\n"
     ]
    }
   ],
   "source": [
    "text_path = './Data3/walrus.txt'\n",
    "\n",
    "i = change_fi(text_path)\n",
    "i = i.load_text()\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9683657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exercise 5\n",
    "Building a simple NLP pipeline\n",
    "\n",
    "For this exercise, you will need NLTK. Don't forget to import it.\n",
    "\n",
    "Write a function called tag_text, which takes raw text as input and returns the tagged text. To do this, make sure you follow the steps below:\n",
    "\n",
    "Tokenize the text.\n",
    "\n",
    "Perform part-of-speech tagging on the list of tokens.\n",
    "\n",
    "Return the tagged text\n",
    "\n",
    "Then test your function using the text snipped below (test_text) as input.\n",
    "\n",
    "Please note that the tags may not be correct and that this is not a mistake on your end, but simply NLP tools not being perfect.\n",
    "\"\"\"\n",
    "import nltk\n",
    "\n",
    "test_text = \"\"\"Shall I compare thee to a summer's day?\n",
    "Thou art more lovely and more temperate:\n",
    "Rough winds do shake the darling buds of May,\n",
    "And summer's lease hath all too short a date:\"\"\"\n",
    "\n",
    "\n",
    "def tag_text(text : str):\n",
    "    \n",
    "    text = nltk.word_tokenize(text)\n",
    "    tagged_text = nltk.pos_tag(text)\n",
    "    \n",
    "    return tagged_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88ed0554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Shall', 'NN'), ('I', 'PRP'), ('compare', 'VBP'), ('thee', 'JJ'), ('to', 'TO'), ('a', 'DT'), ('summer', 'NN'), (\"'s\", 'POS'), ('day', 'NN'), ('?', '.'), ('Thou', 'NNP'), ('art', 'RB'), ('more', 'RBR'), ('lovely', 'RB'), ('and', 'CC'), ('more', 'JJR'), ('temperate', 'NN'), (':', ':'), ('Rough', 'NNP'), ('winds', 'NNS'), ('do', 'VBP'), ('shake', 'VB'), ('the', 'DT'), ('darling', 'VBG'), ('buds', 'NNS'), ('of', 'IN'), ('May', 'NNP'), (',', ','), ('And', 'CC'), ('summer', 'NN'), (\"'s\", 'POS'), ('lease', 'NN'), ('hath', 'NN'), ('all', 'DT'), ('too', 'RB'), ('short', 'JJ'), ('a', 'DT'), ('date', 'NN'), (':', ':')]\n"
     ]
    }
   ],
   "source": [
    "i = tag_text(test_text)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f343ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exercise 6\n",
    "6.a) Explain in your own words the difference between the global and the local scope.\n",
    "\n",
    "[answer]\n",
    "global would be a state that is not constrained to a operation within a particular function\n",
    "or class. this state can be referenced, applied, and changed at any point in the program\n",
    "and that reference, application, or change will be consistant across the program\n",
    "\n",
    "it can also be referenced, applied, or changed within a local function or class without\n",
    "changing the global state that hovers above the rest of the program. essientially being instanced.\n",
    "\n",
    "6.b) What is the difference between the modes 'w' and 'a' when opening a file?\n",
    "\n",
    "[answer]\n",
    "\"w\" is used to write a file. when writing with \"w\" all the contents of the file already there are \n",
    "replaced with the content being used to write to the file.\n",
    "\"a\" is used to append to a file. when appending with \"a\" all the contents of the file already present\n",
    "are kept and the content being used to write to the file is appended to the end unless another space\n",
    "is identified, i.e. after any word 'walrus' or at the beginning to the text.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
